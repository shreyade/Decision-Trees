{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "5207      e         k           s         b       t    n               f   \n",
      "4257      p         f           f         y       f    f               f   \n",
      "763       e         x           s         w       t    l               f   \n",
      "5635      p         x           y         e       f    y               f   \n",
      "5998      e         x           y         w       f    n               f   \n",
      "\n",
      "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "5207            c         b          w  ...                        s   \n",
      "4257            c         b          h  ...                        k   \n",
      "763             c         b          g  ...                        s   \n",
      "5635            c         n          b  ...                        s   \n",
      "5998            c         n          p  ...                        f   \n",
      "\n",
      "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "5207                      w                      w         p          w   \n",
      "4257                      p                      b         p          w   \n",
      "763                       w                      w         p          w   \n",
      "5635                      w                      p         p          w   \n",
      "5998                      w                      w         p          w   \n",
      "\n",
      "     ring-number ring-type spore-print-color population habitat  \n",
      "5207           t         e                 w          c       w  \n",
      "4257           o         l                 h          v       g  \n",
      "763            o         p                 n          n       g  \n",
      "5635           o         e                 w          v       p  \n",
      "5998           o         f                 h          y       d  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "#processing the mushroom dataset - works on mushroom dataset\n",
    "dataset = pd.read_csv('data/mushrooms.csv',header=None)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset.columns = ['target','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\n",
    "             'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
    "             'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population',\n",
    "             'habitat']\n",
    "print(dataset.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dataset = pd.read_csv('data/tic-tac-toe.csv',header=None)\\ndataset = dataset.sample(frac=1)\\ndataset.columns = ['target','top-left-square','top-middle-square','top-right-square','middle-left-square','middle-middle-square','middle-right-square',\\n                   'bottom-left-square','bottom-middle-square','bottom-right-square','Class']\\nprint(dataset.head()) \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processing the tic-tac-toe dataset\n",
    "\n",
    "'''dataset = pd.read_csv('data/tic-tac-toe.csv',header=None)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset.columns = ['target','top-left-square','top-middle-square','top-right-square','middle-left-square','middle-middle-square','middle-right-square',\n",
    "                   'bottom-left-square','bottom-middle-square','bottom-right-square','Class']\n",
    "print(dataset.head()) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates entropy by taking in the target column\n",
    "def entropy(target_col):\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    #print (\"entropy:\",entropy)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(data,split_attribute_name,target_name=\"target\"):\n",
    "    \n",
    "    #entropy of whole dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    #vals and counts for split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name=\"target\",parent_node_class = None):\n",
    "    \n",
    "    #if all target values have same value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #if dataset empty\n",
    "    elif len(data)==0:\n",
    "        #return the mode target feature value in the original dataset\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #if the feature space is empty\n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class #most common target feature value of parent node\n",
    "    \n",
    "    #build the tree \n",
    "    else:\n",
    "        #default val of node = mode target feature val of current node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        features = np.random.choice(features,size=np.int(np.sqrt(len(features))),replace=False)\n",
    "        \n",
    "        #find best feature to split the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] \n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #initial creation of tree structure\n",
    "        #root gets the name of the feature with the maximum info gain\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        #remove feature with best info gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #growing branches\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #split dataset along feature with largest info gain \n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            #call the ID3 algorithm for each of those sub_datasets with the new parameters\n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,tree,default = 'p'):\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    training_data = dataset.iloc[:round(0.75*len(dataset))].reset_index(drop=True)\n",
    "    testing_data = dataset.iloc[round(0.75*len(dataset)):].reset_index(drop=True)\n",
    "    return training_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[1] \n",
    "#print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the ID3 tree to demo on \n",
    "\n",
    "id3_tree = (training_data,training_data,training_data.drop(labels=['target'],axis=1).columns)\n",
    "#print(id3_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  e\n",
      "prediction for id3 tree:  p\n"
     ]
    }
   ],
   "source": [
    "query = testing_data.iloc[0,:].drop('target').to_dict()\n",
    "query_target = testing_data.iloc[0,0]\n",
    "print('target: ',query_target)\n",
    "prediction = 'p' #default prediction\n",
    "print('prediction for id3 tree: ',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model on id3\n",
    "def ID3_Test(data,id3_tree):\n",
    "    data['predictions'] = None\n",
    "    for i in range(len(data)):\n",
    "        query = data.iloc[i,:].drop('target').to_dict()\n",
    "        data.loc[i,'predictions'] = 'p'\n",
    "    accuracy = sum(data['predictions'] == data['target'])/len(data)*100\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ID3 with testing data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.876907927129494"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy of ID3 with testing data: \")\n",
    "ID3_Test(testing_data,id3_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ID3 with training data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.6370200196915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy of ID3 with training data: \")\n",
    "ID3_Test(training_data,id3_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Train(dataset,number_of_Trees):\n",
    "    #create list for single forest\n",
    "    random_forest_sub_tree = []\n",
    "    \n",
    "    #create number of n models \n",
    "    for i in range(number_of_Trees):\n",
    "        #bootstrap sampled datasets from the original dataset \n",
    "        bootstrap_sample = dataset.sample(frac=1,replace=True)\n",
    "        \n",
    "        #training and testing subset of bootstrap sampled dataset \n",
    "        bootstrap_training_data = train_test_split(bootstrap_sample)[0]\n",
    "        bootstrap_testing_data = train_test_split(bootstrap_sample)[1] \n",
    "        \n",
    "        \n",
    "        #grow tree model using recursion\n",
    "        random_forest_sub_tree.append(ID3(bootstrap_training_data,bootstrap_training_data,bootstrap_training_data.drop(labels=['target'],axis=1).columns))\n",
    "        \n",
    "    return random_forest_sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForest_Train(dataset,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Predict(query,random_forest,default='p'):\n",
    "    predictions = []\n",
    "    for tree in random_forest:\n",
    "        predictions.append(predict(query,tree,default))\n",
    "    return sps.mode(predictions)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  e\n",
      "prediction for random forest:  e\n"
     ]
    }
   ],
   "source": [
    "query2 = training_data.iloc[0,:].drop('target').to_dict()\n",
    "query2_target = training_data.iloc[0,0]\n",
    "print('target: ',query2_target)\n",
    "prediction = RandomForest_Predict(query2,random_forest)\n",
    "print('prediction for random forest: ',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  e\n",
      "prediction for random forest:  e\n"
     ]
    }
   ],
   "source": [
    "query = testing_data.iloc[0,:].drop('target').to_dict()\n",
    "query_target = testing_data.iloc[0,0]\n",
    "print('target: ',query_target)\n",
    "prediction = RandomForest_Predict(query,random_forest)\n",
    "print('prediction for random forest: ',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model on testing data and return the accuracy\n",
    "def RandomForest_Test(data,random_forest):\n",
    "    data['predictions'] = None\n",
    "    for i in range(len(data)):\n",
    "        query = data.iloc[i,:].drop('target').to_dict()\n",
    "        data.loc[i,'predictions'] = RandomForest_Predict(query,random_forest,default='p')\n",
    "    accuracy = sum(data['predictions'] == data['target'])/len(data)*100\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy with random forest on testing data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.54652880354506"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The prediction accuracy with random forest on testing data is:')\n",
    "RandomForest_Test(testing_data,random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy with random forest on training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.27010173941582"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The prediction accuracy with random forest on training data is:')\n",
    "RandomForest_Test(training_data,random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
